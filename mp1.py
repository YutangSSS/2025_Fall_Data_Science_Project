# -*- coding: utf-8 -*-
"""MP1.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1cUtvTRywVjYRb4NbgCfQERg1Qky9_TBw

# Wish.com Product Sales Prediction

<div>
<img src="https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F4409738%2Fa89e55ba3a0204c78be0eb154c79a6a0%2FA21ADFF0-AB9D-44E7-ABE0-F2E91CB19E1D.jpeg?generation=1601161987220890&alt=media" width="600"/>
</div>

So in this assignment, you will be working with a tabular dataset. The dataset is not clean, and you will need some preprocessing depending on the models of your choice. The dataset is the wish.com product dataset. We collected the data combined with some available data. Some nosies are added to the dataset. The goal is to predict the product sales - in order to understand customer behaviors and factors contributing to the sales.

The tabular data comes with many columns. To better understand the problem, here is a visual explaination of the product:

<div>
  <img src="https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F1488294%2F308810459ae5232399672ba3eef228ef%2Fannotated-search-results-wish-website.jpg?generation=1598785563117062&alt=media" width="800"/>
</div>

## Upload and read the CSV dataset

Following the same approrach we did in class, drag and drop the CSV dataset file (you can find it on mycourse) to the the folder tab on the left panel. Then lets read the csv file into a dataframe.
"""

# write the code here to import pandas and read the csv file  into a variable
# print out the head of the dataframe
# (1 mark)
import pandas as pd
df=pd.read_csv('product_dataset.csv')
print(df)
df.head()

# print out the column names using the `columns` property
# (1 mark)
df.columns

# calculate the average product rating across the dataset
# hint: slice on the `rating` column and use the `mean()` function on the column.
# In the slide we show examples of the `max()` and `min()` function. `mean` is another
# function that you can directly apply on the column the same way as `max()`.
# (1 mark)
average_rating = df['rating'].mean()

# use the shape property to show the shape of the dataframe
# (1 mark)
shape_of_dataframe = df.shape
print(f'The shape of the DataFrame is: {shape_of_dataframe}')

"""How many numbers returned by the shape property? What does each number mean? (you can double click this cell and directly enter your answer below)

(1 mark)

Answer: 1094

## Data Cleaning - Imputation
"""

# use the `isna` and `sum` function to check the number of missing values
# (1 mark)
df.isna().sum()

"""How many columns contain missing values?

(you can double click this text cell and directly enter your answer below)

(1 mark)

Answer:10



"""

# for the product_color column, replace missing values with color 'green'
# for the price column, replace missing values with '$5'
# for the rating column, replace missing values with the averaged rating (you calculated in the 3rd question)
# for the rating_count column, replace missing values with 0
# assign the imputed dataframe into a new variable
# hint: use the fillna function with dictionary input (see slides for examples)
# (2 marks)

average_rating = df['rating'].mean()

# Fill missing values for specific columns
imputed_df = df.fillna({
    'product_color': 'green',
    'price': '$5',
    'rating': average_rating,
    'rating_count': 0
})

# To verify the changes, print the first few rows
print(imputed_df.head())

# use the isna and sum function again to verify the missing values have been imputed
# for the intended columns
# (1 mark)
missing_values = imputed_df[['product_color', 'price', 'rating', 'rating_count']].isna().sum()

# Print the result
print(missing_values)

"""## Data Cleaning - Transformation"""

# use the `info` function to inspect the data types of your imputed dataframe (1 mark)
imputed_df.info()

"""For the price, retail_price, and units_sold columns, what are their current data types? But what data types would you expect given the problem/column names? (you can double click this cell and directly enter your answer below)

(1 mark)

Answer: Price is object, retail_price and units_sold columns are object , I am expecting the names given are dtypes: float64(4), int64(13), object(17)
"""

# following the examples we had in the slide,
# transform the price column
# into numbers and add it to the imputed dataframe as new columns
# (hint: use the column-based transformation example where we can replace unwanted
# string values by an empty string)
# (1 mark)

imputed_df['new price']=imputed_df['price'].str.replace('$','').astype(float)
imputed_df['new price']

# following the examples we had in the slide,
# transform the retail_price column
# into numbers and add it to the imputed dataframe as new columns
# (hint: use the column-based transformation example where we can replace unwanted
# string values by an empty string)
# (1 mark)

imputed_df['new_retail_price']=imputed_df['retail_price'].str.replace('$','').astype(float)
imputed_df['new_retail_price']

# following the examples we had in the slide,
# transform the units_sold column
# into numbers and add it to the imputed dataframe as new columns
# (hint: use the column-based transformation example where we can replace unwanted
# string values by an empty string)
# (1 mark)
imputed_df['new_units_sold']=imputed_df['units_sold'].str.replace('units','').astype(float)
imputed_df['new_units_sold']

# use the info function again to show that the newly added columns are now becomes
# numeric
# (1 mark)
imputed_df.info()

"""## Data Cleaning - Outliers"""

# use the describe function of the dataframe to investigate the numeric features
# (1 mark)

df.describe()

"""Looking at the rating (supposed to be 1 to 6), does the description information, especiall min/max, make sense to you? if not, what is the problem? (you can double click this cell and directly enter your answer below)

(1 mark)
The rating -100 is extremly low for rating and the max number is high as 20744 for rating count which doesn't make sense.
Answer: 

"""

# print the outliers that have unrealistic rating score:
# (hint use loc with selection conditions - rating less than 0)
# (1 mark)
imputed_df.loc[imputed_df['rating']<0]

# remove the outlier from the dataset
# (use the drop function with the statement you had from last cell - see slides 31 for example )
# (1 mark)
imputed_df.drop(imputed_df.loc[imputed_df['rating']<0].index)

"""

## Meme competition !!!!!!

Please contribute your meme here: You can copy and past the meme directly in the comment box.

https://github.com/CISC-873/Information-2022/issues/4

## Reference:
https://www.kaggle.com/datasets/jmmvutu/summer-products-and-sales-in-ecommerce-wish
"""